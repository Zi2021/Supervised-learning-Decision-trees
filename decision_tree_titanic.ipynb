{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mFPFeEu69axo"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e9C-68Ij9ayD","outputId":"cb08f206-100d-4a4c-f87d-13f2aec390cc"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Load data\n","titanic_df = pd.read_csv('titanic.csv')\n","\n","# Display the first few rows and info\n","print(titanic_df.head())\n","titanic_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CBV7Mx939ayO","outputId":"4e34ffef-0da5-49e5-d52c-379240000dc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 891 entries, 0 to 890\n","Data columns (total 12 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   PassengerId  891 non-null    int64  \n"," 1   Survived     891 non-null    int64  \n"," 2   Pclass       891 non-null    int64  \n"," 3   Name         891 non-null    object \n"," 4   Sex          891 non-null    object \n"," 5   Age          714 non-null    float64\n"," 6   SibSp        891 non-null    int64  \n"," 7   Parch        891 non-null    int64  \n"," 8   Ticket       891 non-null    object \n"," 9   Fare         891 non-null    float64\n"," 10  Cabin        204 non-null    object \n"," 11  Embarked     889 non-null    object \n","dtypes: float64(2), int64(5), object(5)\n","memory usage: 83.7+ KB\n"]}],"source":["# Data cleaning\n","titanic_df.isnull().sum()\n","titanic_df['Embarked'].fillna(titanic_df['Embarked'].mode()[0], inplace=True)\n","titanic_df.drop_duplicates(inplace=True)\n","\n","# Outlier detection\n","sns.boxplot(titanic_df.iloc[:,1:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EhNnIWET9ayS"},"outputs":[],"source":["# Select relevant features\n","features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n","df = titanic_df[features]\n","\n","# Convert categorical variables\n","df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n","df['Embarked'] = df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n","\n","# Handle missing values\n","df['Age'].fillna(df['Age'].median(), inplace=True)\n","df['Fare'].fillna(df['Fare'].median(), inplace=True)\n","df.dropna(inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"zFZ50hDg9aye"},"source":["### One-Hot Encoding\n","One-hot encoding is a technique used to ensure that categorical variables are better represented in the machine. Let's take a look at the \"Sex\" column"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxl62Q0-9ay1","outputId":"1b2e62ad-3707-424d-fc21-26d413fc9221"},"outputs":[{"data":{"text/plain":["array(['male', 'female'], dtype=object)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Encoding categorical data\n","titanic_df = pd.get_dummies(titanic_df, columns=['Embarked', 'Sex'])\n","titanic_df['Pclass'] = LabelEncoder().fit_transform(titanic_df['Pclass'])\n","\n","# Check the resulting dataframe structure\n","print(df.head())"]},{"cell_type":"markdown","metadata":{"id":"sXIAVO4Z9ay8"},"source":["Machine Learning classifiers don't know how to handle strings. As a result, you need to convert it into a categorical representation. There are two main ways to go about this:\n","\n","Label Encoding: Assigning, for example, 0 for \"male\" and 1 for \"female\". The problem here is it intrinsically makes one category \"larger than\" the other category.\n","\n","One-hot encoding: Assigning, for example, [1, 0] for \"male\" and [0, 1] for female. In this case, you have an array of size (n_categories,) and you represent a 1 in the correct index, and 0 elsewhere. In Pandas, this would show as extra columns. For example, rather than having a \"Sex\" column, it would be a \"Sex_male\" and \"Sex_female\" column. Then, if the person is male, it would simply show as a 1 in the \"Sex_male\" column and a 0 in the \"Sex_female\" column.\n","\n","There is a nice and easy method that does this in pandas: get_dummies()"]},{"cell_type":"markdown","metadata":{"id":"4b3ItGkb9azJ"},"source":["Now, we do the same to the \"Embarked\" column."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Split the data\n","X = titanic_df.drop('Survived', axis=1)\n","y = titanic_df['Survived']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train decision tree model\n","model = DecisionTreeClassifier()\n","model.fit(X_train, y_train)\n","\n","# Plot decision tree\n","import matplotlib.pyplot as plt\n","from sklearn import tree\n","plt.figure(figsize=(12, 8))\n","tree.plot_tree(model, filled=True, feature_names=X_train.columns)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluate development set accuracy\n","# Evaluate model\n","y_pred = model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Test Set Accuracy: {accuracy:.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Experiment with different max depths\n","# Hyperparameter tuning (max depth)\n","max_depths = range(2, 11)\n","train_accuracies = []\n","test_accuracies = []\n","\n","for depth in max_depths:\n","    model = DecisionTreeClassifier(max_depth=depth)\n","    model.fit(X_train, y_train)\n","    train_pred = model.predict(X_train)\n","    test_pred = model.predict(X_test)\n","    train_accuracies.append(accuracy_score(y_train, train_pred))\n","    test_accuracies.append(accuracy_score(y_test, test_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot training and development accuracies\n","plt.figure(figsize=(10, 5))\n","plt.plot(max_depths, train_accuracies, label='Training Accuracy', marker='o')\n","plt.plot(max_depths, test_accuracies, label='Test Accuracy', marker='o')\n","plt.xlabel('Max Depth')\n","plt.ylabel('Accuracy')\n","plt.title('Training and Test Accuracies vs. Max Depth')\n","plt.legend()\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Analyze line shapes and interpret results\n","print(\"Line Shape Analysis:\")\n","if train_accuracies[-1] < train_accuracies[-2]:\n","    print(\"Training accuracy decreases at higher max_depth, indicating overfitting.\")\n","else:\n","    print(\"Training accuracy continues to improve or remains stable.\")\n","\n","if test_accuracies[-1] > test_accuracies[-2]:\n","    print(\"Test accuracy improves at higher max_depth, indicating optimal performance.\")\n","elif test_accuracies[-1] == test_accuracies[-2]:\n","    print(\"Test accuracy remains stable at higher max_depth, indicating optimal performance.\")\n","else:\n","    print(\"Test accuracy decreases at higher max_depth, indicating overfitting.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Determine best max depth\n","best_depth = max_depths[test_accuracies.index(max(test_accuracies))]\n","print(f'Best Max Depth: {best_depth}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train final model with best max depth\n","final_model = DecisionTreeClassifier(max_depth=best_depth)\n","final_model.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluate final model\n","y_final_pred = final_model.predict(X_test)\n","final_accuracy = accuracy_score(y_test, y_final_pred)\n","print(f'Final Test Set Accuracy: {final_accuracy:.2f}')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"cvML","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1904059d3876957b542b45423f2a26c6c4608f5e11cc75420e543fa77f94b066"}}},"nbformat":4,"nbformat_minor":0}
